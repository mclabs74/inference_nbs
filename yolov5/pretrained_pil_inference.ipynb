{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pretrained_pil_inference",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJMRl2aw9BLWwQcYbjBxHk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mclabs74/inference_nbs/blob/main/yolov5/pretrained_pil_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k25eRV2CDtMW"
      },
      "source": [
        "based on https://github.com/ultralytics/yolov5/issues/36"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMezg6RGxPzU"
      },
      "source": [
        "### install yolo5 requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5lQP14OnE-H"
      },
      "source": [
        "!pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2w22vCXxUj2"
      },
      "source": [
        "### Download model\n",
        "Download the model, if it does not exist, and instantiate model object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abc--X0nF9es"
      },
      "source": [
        "import cv2\n",
        "import torch\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "# folder for model folders. check to see if it exists, and if so\n",
        "# don't download\n",
        "model_path = Path(\"./model\")\n",
        "model_folder = Path(model_path/\"ultralytics_yolov5_master\")\n",
        "if model_folder.is_dir() == False:\n",
        "    torch.hub.set_dir(model_path)\n",
        "\n",
        "# instantiate model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA_caCMYxAru"
      },
      "source": [
        "### inference api decorators\n",
        "Install inference api decorators. This is necessary for the inference servers to know your predict datatypes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5auCaWFcSnl"
      },
      "source": [
        "!pip install -q git+https://github.com/matthewchung74/inference_params.git\n",
        "from inference_params.inference_params import inference_test, FieldType, inference_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkyfH7kNyLu4"
      },
      "source": [
        "### Predict function\n",
        "Define your predict function and decorate with inference wrapper and input/output types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAk2UoWhnFsw"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import io\n",
        "import base64\n",
        "import json\n",
        "\n",
        "\n",
        "# text input will be the label for the app input\n",
        "input = {\"image input\": FieldType.PIL}\n",
        "# result will be the label for the app output\n",
        "output = {\"result image\": FieldType.PIL, \"result text\": FieldType.Text}\n",
        "\n",
        "@inference_predict(input=input, output=output)\n",
        "def predict(params):\n",
        "    img = params['image input']\n",
        "    results = model(img)  # inference\n",
        "    results.imgs # array of original images (as np array) passed to model for inference\n",
        "    results.render()  # updates results.imgs with boxes and labels\n",
        "    pil_image = Image.fromarray(results.imgs[0])\n",
        "    records = results.pandas().xyxy[0].to_csv()\n",
        "    return {\"result image\": pil_image, \"result text\": records}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJI_YapKyWDt"
      },
      "source": [
        "### Test it\n",
        "Make sure you have your `in_colab` functions so your tests are not executed on every request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UNMjrAzFTy9"
      },
      "source": [
        "from inference_params.inference_params import in_colab\n",
        "\n",
        "if in_colab():\n",
        "    torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/zidane.jpg', 'zidane.jpg')\n",
        "    img = Image.open('zidane.jpg')  # PIL image\n",
        "\n",
        "    from inference_params.inference_params import in_colab\n",
        "    from matplotlib.pyplot import imshow\n",
        "    import numpy as np\n",
        "\n",
        "    from google.colab.patches import cv2_imshow\n",
        "    result, duration = predict({'image input': img})\n",
        "    result_image = result['result image']\n",
        "    result_text = result['result text']\n",
        "\n",
        "    print(result_text)\n",
        "    display(result_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_6J97WRzJRV"
      },
      "source": [
        "### Run Inference Test\n",
        "This function `inference_test` saves your input and output types to disk, which are needed for inference to know your datatypes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2BtcXbdcZX_"
      },
      "source": [
        "from inference_params.inference_params import in_colab\n",
        "\n",
        "if in_colab():\n",
        "    inference_test(predict_func=predict, params={'image input': img})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4N0zG8tza5u"
      },
      "source": [
        "### Clear outputs\n",
        "You should clear your outputs so your notebook is not too large. Go to File->Clear Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ8T6yXSzmN5"
      },
      "source": [
        "### Commit your file to github.\n",
        "Then go to inference.codes to upload your file."
      ]
    }
  ]
}